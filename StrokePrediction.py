# -*- coding: utf-8 -*-
"""DataMiningProjectExtra.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16rhKVf8LZrzy75oTeKw-ZF57U3bEdq_n
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from scipy import stats
import random
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier,plot_tree
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.tree import export_text
from sklearn.feature_selection import chi2
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import mutual_info_classif
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_selection import VarianceThreshold
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

from google.colab import files

upload = files.upload()

data = pd.read_csv("healthcare-dataset-stroke-data.csv", header='infer')

print('Number of instances = ',data.shape[0])
print('Number of attributes = ',data.shape[1],"\n")
# To get then number of missing values
print(data.isna().sum())

# Impute missing values in the 'bmi' column with the mean
data['bmi'].fillna(data['bmi'].mean(), inplace=True)

# Calculate the mean of the 'bmi' attribute
mean_bmi = data['bmi'].mean()

print("Mean BMI:", mean_bmi)
# Missing Values Sorted
print(data.isna().sum()==0)

for i in data.columns:
    if data[i].dtype == "object":
        print(data[i].unique())

old_instances = data.shape[0]
print('Number of old instances = ', old_instances)
drop_conditions = {
    'gender': 'Other',
    'smoking_status': 'Unknown',
    'work_type':'children'
}

for column_name, value in drop_conditions.items():
    filtered_data = data.loc[data[column_name] == value]
    data.drop(filtered_data.index, inplace=True)
    print(f"Dropped Data {value} for column {column_name}")
print(f"dropped {old_instances-data.shape[0]}")
print('Number of new instances = ', data.shape[0])

print('Number of rows before discarding duplicates = %d' % (data.shape[0]))
data = data.drop_duplicates()
print('Number of rows after discarding duplicates = %d' % (data.shape[0]))

rows_to_duplicate = data.sample(n=random.randint(50,500), replace=True)
data = pd.concat([data, rows_to_duplicate] * random.randint(10,200), ignore_index=True)

# Shuffle the DataFrame to mix the duplicated rows
data = data.sample(frac=1).reset_index(drop=True)

print('Number of rows before discarding duplicates = %d' % (data.shape[0]))
data = data.drop_duplicates()
print('Number of rows after discarding duplicates = %d' % (data.shape[0]))

data.drop("id", axis=1, inplace=True)

data['stroke'] = ['YES' if i == 1 else 'NO' for i in data['stroke']]

# distribution of the label `stroke`
plt.figure(figsize=(4,4))
sns.countplot(data=data, x='stroke')
plt.title('Distribution of Stroke vs Normal', fontsize=10)
plt.grid(alpha=0.4)

# Count the number of rows with stroke = 1 and stroke = 0
stroke_count = data[data['stroke'] == "YES"].shape[0]
Normal_count = data[data['stroke'] == "NO"].shape[0]

# Find the difference in counts and duplicate rows with stroke = 1
diff_count = Normal_count - stroke_count
rows_to_duplicate = data[data['stroke'] == "YES"].sample(n=diff_count, replace=True)

# Concatenate the duplicated rows with the original dataframe
data = pd.concat([data, rows_to_duplicate], ignore_index=True)

# Shuffle the DataFrame to mix the duplicated rows
data = data.sample(frac=1).reset_index(drop=True)

# distribution of the label `stroke`
plt.figure(figsize=(4,4))
sns.countplot(data=data, x='stroke')
plt.title('Distribution of Stroke vs Normal', fontsize=10)
plt.grid(alpha=0.4)

print('Number of rows after balancing:', data.shape)

columns_to_standardize = ['age', 'avg_glucose_level', 'bmi']
scaler = StandardScaler()
data[columns_to_standardize] = scaler.fit_transform(data[columns_to_standardize])

numeric_columns = data.select_dtypes(include=[np.number]).columns
sns.boxplot(data=data[numeric_columns])
plt.show()

from scipy import stats

threshold = 5
# Identify and filter outliers
outliers = (np.abs(stats.zscore(data[numeric_columns])) > threshold).any(axis=1)

# Print or visualize the index of outlier values in the original dataset
print("Indices of Outlier Values:")
print(data.index[outliers])

# Print the number of rows before removing outliers
print('Number of rows before removing outliers = ', data.shape[0])

# Drop outliers from the original data
data_no_outliers = data[~outliers]

# Print the number of rows after removing outliers
print('Number of rows after removing outliers = ', data_no_outliers.shape[0])

# Check for NaN values after outlier removal
print("NaN values after outlier removal:")
print(data_no_outliers.isnull().sum())

# Update data with the cleaned dataset
data = data_no_outliers.copy()

correlation_matrix = data.corr()
sns.set(style="white")  # Set the style of the visualization
plt.figure(figsize=(5, 5))

# Creating a heatmap with a color map
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)

plt.show()

variance_per_attribute = data.var()
print("Variance for each attribute:")
print(variance_per_attribute)

data.head()

pd.crosstab([data['hypertension']],data['stroke'])

y = data['stroke']
X = data.drop('stroke', axis=1)

# One-hot encode categorical variables
X = pd.get_dummies(X)

# Calculate information gain for the filtered data
information_gain = mutual_info_classif(X, y)

# Display bar plot
plt.bar(X.columns, information_gain)
plt.xlabel('Feature')
plt.ylabel('Information Gain')
plt.title('Information Gain per Feature')
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better visibility
plt.show()

# Display information gain values
print("Information Gain for each feature\n")
for i in range(len(X.columns)):
    print(X.columns[i], " : ", information_gain[i])

# Create a copy of the original DataFrame
scaled_data = data.copy()

# Extract numerical columns for scaling
numerical_columns = scaled_data.select_dtypes(include='float64').columns

# Apply Min-Max scaling to numerical features
scaler = MinMaxScaler()
scaled_data[numerical_columns] = scaler.fit_transform(scaled_data[numerical_columns])

# Separate target variable and features in the scaled dataset
y_scaled = scaled_data['stroke']
X_scaled = scaled_data.drop('stroke', axis=1)

# One-hot encode categorical variables in the scaled dataset
X_scaled = pd.get_dummies(X_scaled)

# Calculate chi-squared scores and p-values for the scaled features
chi2_scores_scaled, p_values_scaled = chi2(X_scaled, y_scaled)

# Display chi-squared scores for each feature in the scaled dataset
plt.bar(X_scaled.columns, chi2_scores_scaled)
plt.title("Chi-squared scores for each feature (scaled)")
plt.xlabel("Features")
plt.ylabel("Chi-squared Score")
plt.xticks(rotation=45, ha='right')
plt.show()

print("Variances of each feature:")
print(X.var())

variance_threshold = 0.01

# Apply variance thresholding
selector = VarianceThreshold(threshold=variance_threshold)
X_high_variance = selector.fit_transform(X)

# Print the remaining features after variance thresholding
selected_features = X.columns[selector.get_support()]
print("\nSelected features after variance thresholding:", selected_features)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Use Recursive Feature Elimination (RFE) with a Decision Tree Classifier
model_for_rfe = DecisionTreeClassifier(random_state=42, criterion='gini')

# Initialize RFE with the desired number of features to select
rfe = RFE(model_for_rfe, n_features_to_select=5)

# Fit RFE on the training data and transform the features
X_train_rfe = rfe.fit_transform(X_train, y_train)

# Get the selected features
selected_features = X_train.columns[rfe.support_]

# Apply the same feature selection to the testing data
X_test_rfe = X_test[selected_features]

# Create a DataFrame with the selected features from RFE on training data
final_df_train = pd.DataFrame(X_train_rfe, columns=selected_features)

# Apply the same feature selection to the testing data
final_df_test = pd.DataFrame(X_test_rfe, columns=selected_features)

print("\nDataFrame with Selected Features from RFE (Testing Data):")
print(final_df_test.columns)

# Create and train the KNN model
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_knn = knn_model.predict(X_test)

# Evaluate the KNN model
accuracy_knn = accuracy_score(y_test, y_pred_knn)
print(f"KNN Accuracy: {accuracy_knn:.4f}")

# Confusion Matrix
conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)
plt.figure(figsize=(6, 6))
sns.heatmap(conf_matrix_knn, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

# Classification Report
class_report_knn = classification_report(y_test, y_pred_knn)
print("\nClassification Report (KNN):")
print(class_report_knn)

X.head()

data.head()

model_decision_tree = DecisionTreeClassifier(random_state=42)
model_decision_tree.fit(X_train[selected_features], y_train)

# Make predictions on the test set using Decision Tree
y_pred_decision_tree = model_decision_tree.predict(X_test[selected_features])

# Evaluate the Decision Tree model
accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)
print(f"Decision Tree Accuracy: {accuracy_decision_tree:.4f}")

# Visualize the Decision Tree
plt.figure(figsize=(15, 10))
plot_tree(model_decision_tree, feature_names=selected_features, class_names=['No Stroke', 'Stroke'], filled=True, rounded=True)
plt.title("Decision Tree Visualization")
plt.show()

conf_matrix = confusion_matrix(y_test, y_pred_decision_tree)

# Visualize Confusion Matrix
plt.figure(figsize=(6, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

# Classification Report
class_report = classification_report(y_test, y_pred_decision_tree)
print("Classification Report:")
print(class_report)

# Cross-Validation
cv_scores = cross_val_score(model_decision_tree, X[selected_features], y, cv=5, scoring='accuracy')
print("Cross-Validation Scores:", cv_scores)
print("Mean Cross-Validation Score:", np.mean(cv_scores))
